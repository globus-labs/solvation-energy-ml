{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPNNs for Predicting Partial Charges\n",
    "This notebook creates neural networks for predicting the partial charges of each molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from nfp.preprocessing import SmilesPreprocessor\n",
    "from nfp.models import GraphModel\n",
    "from nfp.layers import (MessageLayer, GRUStep, Set2Set, ReduceAtomToMol, \n",
    "                        Embedding2D, Embedding2DCompressed, Squeeze)\n",
    "from keras import backend as K\n",
    "from keras.layers import (Add, Input, Dense, BatchNormalization, Reshape, Concatenate,\n",
    "                          Activation, Dropout, Embedding, Lambda)\n",
    "from jcesr_ml.benchmark import load_benchmark_data\n",
    "from jcesr_ml.mpnn import save_model_files, AtomicPropertySequence, TotalChargeLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Datasets\n",
    "We need the datasets for determining the shape of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _ = load_benchmark_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Preprocessing Tools\n",
    "These tools convert the SMILES representation of a molecule into a set of features needed for the graph training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SmilesPreprocessor(explicit_hs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117232/117232 [00:56<00:00, 2063.07it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor.fit(train_data['smiles_0']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Utility Functions\n",
    "Make a model-building function and a tool to save a model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(preprocessor, embedding=128, dense_layers=(64, 32),\n",
    "             message_steps=6, activation='softplus'):\n",
    "    \"\"\"Build a MPNN Keras model\n",
    "    \n",
    "    Adapted from: https://github.com/NREL/nfp/blob/master/examples/run_2D_model_noatom_bn.py\n",
    "    \n",
    "    Args:\n",
    "        preprocessor (SmilesPreprocessor): Tool to generate inputs from SMILES string\n",
    "        embedding (int): Size of the atom/bond embedding\n",
    "        mol_features (int): Number of features to use to describe a molecule\n",
    "        message_steps (int): Number of message-passing steps\n",
    "    \"\"\"\n",
    "    \n",
    "    # Raw (integer) graph inputs\n",
    "    #  node_graph_indices - Maps the atom index to which molecule it came from\n",
    "    #  atom_types - Categorical type of each atom\n",
    "    #  bond_types - Categorical type of each bond\n",
    "    #  connectivity - Atoms on each end of each bond\n",
    "    node_graph_indices = Input(shape=(1,), name='node_graph_indices', dtype='int32')\n",
    "    atom_types = Input(shape=(1,), name='atom', dtype='int32')\n",
    "    bond_types = Input(shape=(1,), name='bond', dtype='int32')\n",
    "    connectivity = Input(shape=(2,), name='connectivity', dtype='int32')\n",
    "\n",
    "    # The \"indices\" and \"type\" inputs have 1 feature per \"entry\"\n",
    "    #  The Squeeze layer removes this singleton dimension to make the data easier to use\n",
    "    squeeze = Squeeze()\n",
    "    snode_graph_indices = squeeze(node_graph_indices)\n",
    "    satom_types = squeeze(atom_types)\n",
    "    sbond_types = squeeze(bond_types)\n",
    "\n",
    "    # Create the embedding for each atom type\n",
    "    atom_state = Embedding(\n",
    "        preprocessor.atom_classes,\n",
    "        embedding, name='atom_embedding')(satom_types)\n",
    "\n",
    "    # Create the embedding for each bond type\n",
    "    bond_matrix = Embedding2DCompressed(\n",
    "        preprocessor.bond_classes,\n",
    "        embedding, name='bond_embedding')(sbond_types)\n",
    "\n",
    "    # The core of the message passing framework: Recurrent and Message-passing layers\n",
    "    #  The Message Layer computes an update message for each atom given the state of it's neighbors\n",
    "    #  The Reccurent Layer (GRUStep) computes how the state of the atom changes given a message\n",
    "    atom_rnn_layer = GRUStep(embedding)\n",
    "    message_layer = MessageLayer(reducer='sum')\n",
    "\n",
    "    # Perform the message passing\n",
    "    for _ in range(message_steps):\n",
    "\n",
    "        # Get the message updates to each atom\n",
    "        message = message_layer([atom_state, bond_matrix, connectivity])\n",
    "\n",
    "        # Update memory and atom states\n",
    "        atom_state = atom_rnn_layer([message, atom_state])\n",
    "\n",
    "    # After the message passing step, we reduce the atomic representation to one feature per atom\n",
    "    atom_out = Dense(embedding, activation='sigmoid')(atom_state)\n",
    "    \n",
    "    for layer_size in dense_layers:\n",
    "        atom_out = Dense(layer_size, activation=activation)(atom_out)\n",
    "    \n",
    "    # One feature per atom\n",
    "    atom_out = Dense(1, activation='linear')(atom_out)\n",
    "\n",
    "    return GraphModel([node_graph_indices, atom_types, bond_types, connectivity], [atom_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lward/miniconda3/envs/jcesr_ml/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_fn(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already output. Skipping\n"
     ]
    }
   ],
   "source": [
    "save_model_files('standard', preprocessor, model, output_props=['mapped_charges'], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge-Balanced MPNN\n",
    "An MPNN where it ensures that the total charge on each molecule is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(preprocessor, embedding=128, dense_layers=(64, 32),\n",
    "             message_steps=6, activation='softplus'):\n",
    "    \"\"\"Build a MPNN Keras model\n",
    "    \n",
    "    Adapted from: https://github.com/NREL/nfp/blob/master/examples/run_2D_model_noatom_bn.py\n",
    "    \n",
    "    Args:\n",
    "        preprocessor (SmilesPreprocessor): Tool to generate inputs from SMILES string\n",
    "        embedding (int): Size of the atom/bond embedding\n",
    "        mol_features (int): Number of features to use to describe a molecule\n",
    "        message_steps (int): Number of message-passing steps\n",
    "    \"\"\"\n",
    "    \n",
    "    # Raw (integer) graph inputs\n",
    "    #  node_graph_indices - Maps the atom index to which molecule it came from\n",
    "    #  atom_types - Categorical type of each atom\n",
    "    #  bond_types - Categorical type of each bond\n",
    "    #  connectivity - Atoms on each end of each bond\n",
    "    node_graph_indices = Input(shape=(1,), name='node_graph_indices', dtype='int32')\n",
    "    atom_types = Input(shape=(1,), name='atom', dtype='int32')\n",
    "    bond_types = Input(shape=(1,), name='bond', dtype='int32')\n",
    "    connectivity = Input(shape=(2,), name='connectivity', dtype='int32')\n",
    "\n",
    "    # The \"indices\" and \"type\" inputs have 1 feature per \"entry\"\n",
    "    #  The Squeeze layer removes this singleton dimension to make the data easier to use\n",
    "    squeeze = Squeeze()\n",
    "    snode_graph_indices = squeeze(node_graph_indices)\n",
    "    satom_types = squeeze(atom_types)\n",
    "    sbond_types = squeeze(bond_types)\n",
    "\n",
    "    # Create the embedding for each atom type\n",
    "    atom_state = Embedding(\n",
    "        preprocessor.atom_classes,\n",
    "        embedding, name='atom_embedding')(satom_types)\n",
    "\n",
    "    # Create the embedding for each bond type\n",
    "    bond_matrix = Embedding2DCompressed(\n",
    "        preprocessor.bond_classes,\n",
    "        embedding, name='bond_embedding')(sbond_types)\n",
    "\n",
    "    # The core of the message passing framework: Recurrent and Message-passing layers\n",
    "    #  The Message Layer computes an update message for each atom given the state of it's neighbors\n",
    "    #  The Reccurent Layer (GRUStep) computes how the state of the atom changes given a message\n",
    "    atom_rnn_layer = GRUStep(embedding)\n",
    "    message_layer = MessageLayer(reducer='sum')\n",
    "\n",
    "    # Perform the message passing\n",
    "    for _ in range(message_steps):\n",
    "\n",
    "        # Get the message updates to each atom\n",
    "        message = message_layer([atom_state, bond_matrix, connectivity])\n",
    "\n",
    "        # Update memory and atom states\n",
    "        atom_state = atom_rnn_layer([message, atom_state])\n",
    "\n",
    "    # After the message passing step, we reduce the atomic representation to one feature per atom\n",
    "    atom_out = Dense(embedding, activation='sigmoid')(atom_state)\n",
    "    \n",
    "    for layer_size in dense_layers:\n",
    "        atom_out = Dense(layer_size, activation=activation)(atom_out)\n",
    "    \n",
    "    # One feature per atom\n",
    "    atom_out = Dense(1, activation='linear')(atom_out)\n",
    "    \n",
    "    # Make sure the molecules are charge balanced\n",
    "    atom_out = TotalChargeLayer()([snode_graph_indices, atom_out])\n",
    "\n",
    "    return GraphModel([node_graph_indices, atom_types, bond_types, connectivity], [atom_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_fn(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already output. Skipping\n"
     ]
    }
   ],
   "source": [
    "save_model_files('charge-balanced', preprocessor, model, output_props=['mapped_charges'], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
