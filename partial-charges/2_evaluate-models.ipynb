{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Partial Charge Prediction\n",
    "Test how well our models for partial charges are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from jcesr_ml.mpnn import set_custom_objects, run_model\n",
    "from jcesr_ml.benchmark import load_benchmark_data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import load_model\n",
    "from ase.units import eV, Hartree\n",
    "from time import perf_counter\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_custom_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Datasets\n",
    "We need the datasets for determining the shape of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle('mapped_charges_dataset.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.query('in_holdout', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Baselines\n",
    "See how good assuming all networks to be uncharged is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of all charges  0.19\n"
     ]
    }
   ],
   "source": [
    "charge_mae = test_data['atomic_charges'].apply(np.array).apply(np.abs).apply(sum).sum() / test_data['n_atom'].sum()\n",
    "print(f'MAE of all charges {charge_mae: .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate partial charges with [Gasteiger Charges](https://www.rdkit.org/docs/source/rdkit.Chem.rdPartialCharges.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gasteiger_charges(smiles):\n",
    "    \"\"\"Compute the Gasteiger partial charges for a molecule\n",
    "    \n",
    "    Args:\n",
    "        smiles (str): SMILES string of the molecule\n",
    "    Returns:\n",
    "        (ndarray) Charges on each atom\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the SMILES string\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    \n",
    "    # Compute the charges\n",
    "    AllChem.ComputeGasteigerCharges(mol)\n",
    "    \n",
    "    # Extract the charges\n",
    "    return np.array([float(atom.GetProp('_GasteigerCharge')) for atom in mol.GetAtoms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.03 s, sys: 5.48 ms, total: 6.03 s\n",
      "Wall time: 6.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data['gasteiger_charges'] = test_data['smiles_0'].apply(compute_gasteiger_charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gastier MAE: 0.124\n"
     ]
    }
   ],
   "source": [
    "gastier_charges_mae = mean_absolute_error(np.hstack(test_data['gasteiger_charges']), np.hstack(test_data['mapped_charges']))\n",
    "print(f'Gastier MAE: {gastier_charges_mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate All Models\n",
    "See if our deep learning model is better than the Gasteiger partial charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glob(os.path.join('networks', '**', 'best_model.h5'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(path):\n",
    "    \"\"\"Given a log file, parse the settings for the network and the epoch time / ending val_loss\n",
    "    \n",
    "    Args:\n",
    "        path (str): Get the path \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the metadata from directory structure\n",
    "    path = Path(path)\n",
    "    parents = list(path.parents)\n",
    "    metadata = [p.name for p in parents[:-3]]\n",
    "    metadata = dict([(x[-1], '-'.join(x[:-1])) for x in map(lambda x: x.split(\"-\"), metadata)])\n",
    "    metadata['path'] = str(path.parent)\n",
    "    metadata['network'] = parents[-3].name\n",
    "    \n",
    "    # Convert numerical values\n",
    "    for k in ['nodes', 'entries', 'batch_size']:\n",
    "        metadata[k] = int(metadata[k])\n",
    "    \n",
    "    # Score the model on the target variable\n",
    "    with open(parents[-3].joinpath('options.json')) as fp:\n",
    "        options = json.load(fp)\n",
    "    output = options['output_props']\n",
    "    metadata['output'] = output\n",
    "    \n",
    "    # Load in the log\n",
    "    log = pd.read_csv(path.parent.joinpath('log.csv'))\n",
    "    metadata['epochs'] = len(log)\n",
    "    metadata['median_epoch_time'] = np.percentile(log['epoch_time'], 50)\n",
    "    metadata['total_time'] = log['epoch_time'].sum()\n",
    "    metadata['cpu-hrs'] = metadata['total_time'] * metadata['nodes'] / 3600 * 64\n",
    "    metadata['best_loss'] = log['val_loss'].min()\n",
    "    metadata['best_loss_epoch'] = log['val_loss'].idxmin()\n",
    "    \n",
    "    # Check whether the network had finished training\n",
    "    metadata['finished'] = os.path.isfile(path.parent.joinpath('finished'))\n",
    "    \n",
    "    # Load the converter\n",
    "    with open(parents[-3].joinpath('converter.pkl'), 'rb') as fp:\n",
    "        converter = pkl.load(fp)\n",
    "    \n",
    "    # Load in the model and run it on the test set\n",
    "    directory = path.parent\n",
    "    y_true = np.hstack(test_data['mapped_charges'])\n",
    "    for name in ['best_model.h5', 'checkpoint.h5']:\n",
    "        tag = '-best' if name.startswith('best') else '-last'\n",
    "        \n",
    "        model = load_model(str(path.parent.joinpath(name)))\n",
    "        start_time = perf_counter()\n",
    "        y_pred = np.squeeze(run_model(model, converter, test_data['smiles_0'], chunk_size=1024))\n",
    "        metadata[f'mae{tag}'] = mean_absolute_error(y_pred, y_true)\n",
    "        metadata[f'eval_time{tag}'] = perf_counter() - start_time\n",
    "        \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A/home/lward/miniconda3/envs/jcesr_ml/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\n",
      " 25%|██▌       | 1/4 [00:32<01:36, 32.23s/it]\u001b[A/home/lward/miniconda3/envs/jcesr_ml/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/lward/miniconda3/envs/jcesr_ml/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\n",
      "100%|██████████| 4/4 [01:09<00:00, 17.27s/it]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame([score_model(m) for m in tqdm(models) if 'standard' in m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mae-best</th>\n",
       "      <th>mae-last</th>\n",
       "      <th>cpu-hrs</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standard</td>\n",
       "      <td>1.00e-04</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>110.938707</td>\n",
       "      <td>6240.302262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standard</td>\n",
       "      <td>1.00e-04</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>2113.665788</td>\n",
       "      <td>14861.712574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    network learning_rate  batch_size  mae-best  mae-last      cpu-hrs  \\\n",
       "0  standard      1.00e-04        1024  0.016461  0.017548   110.938707   \n",
       "1  standard      1.00e-04        8192  0.009501  0.009756  2113.665788   \n",
       "\n",
       "     total_time  \n",
       "0   6240.302262  \n",
       "1  14861.712574  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['network', 'learning_rate', 'batch_size', 'mae-best', 'mae-last', 'cpu-hrs', 'total_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding*: Our \"standard\" network does pretty well. MAEs less than 10% of the variation in the dataset and better than the Gasteiger charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
